
```sql
sqlite3 :memory: "SELECT number, title, body, body_url, author_login, created_at, updated_at, labels_src, labels FROM github_issue WHERE repository_full_name = 'irthomasthomas/undecidability';"
```

```sql
sqlite3 :memory: "ATTACH DATABASE '/home/thomas/steampipe/github-issues.db' AS db2; INSERT INTO db2.github_issues SELECT number, title, body, body_url, author_login, created_at, updated_at, labels_src, labels FROM github_issue WHERE repository_full_name = 'irthomasthomas/undecidability';"
```

```shell
llm embed-multi gh-issues \
-d github-issues.db \
--sql 'SELECT number, title, body FROM github_issues' \
-m jina-embeddings-v2-base-en \
--batch-size 7 \
--store
```
#### Storing content and metadata

By default, only the entry ID and the embedding vector are stored in the database table.

You can store a copy of the original text in the `content` column by passing the `--store` option:

```bash
llm embed phrases hound -c 'my happy hound' --store
```
You can also store a JSON object containing arbitrary metadata in the `metadata` column by passing the `--metadata` option. This example uses both `--store` and `--metadata` options:

```shell
llm embed phrases hound \
  -m 3-small \
  -c 'my happy hound' \
  --metadata '{"name": "Hound"}' \
  --store
```
Data stored in this way will be returned by calls to `llm similar`, for example:
```bash
llm similar phrases -c 'hound'
```
```
{"id": "hound", "score": 0.8484683588631485, "content": "my happy hound", "metadata": {"name": "Hound"}}
```

(embeddings-cli-embed-multi)=
## llm embed-multi

`llm embed-multi` can be used to embed multiple strings at once, taking advantage of any efficiencies that the embedding model may provide when processing multiple strings.

This command can be called in one of three ways:

1. With a CSV, TSV, JSON or newline-delimited JSON file
2. With a SQLite database and a SQL query
3. With one or more paths to directories, each accompanied by a glob pattern

All three mechanisms support these options:

- `-m model_id` the embedding model to use
- `-d database.db` specify a different db to store the embeddings in
- `--store` to store the original content in the embeddings table in addition to the embedding vector
- `--prefix` to prepend a prefix to the stored ID of each item
- `--batch-size SIZE`

```bash
cat mydata.json | llm embed-multi items -
```

```shell
llm similar -d github-issues.db gh-issues -c "https://github.com/datastax/astra-assistants-api\nA backend implementation of the OpenAI beta Assistants API" -n 2
```


# Steampipe instructions

